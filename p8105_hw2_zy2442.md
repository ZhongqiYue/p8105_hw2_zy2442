Homework 2
================
Zhongqi Yue

``` r
library(tidyverse)
```

    ## ── Attaching packages ───────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ──────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2018 and 2017.

``` r
precip_2018 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
    ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
    ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018,precip_2017) 

left_join(precip_df, month_df, by = "month" )
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data. The
median number of sports balls found in a dumpster in 2017 was 8 The
total precipitation in 2018 was 70.33 inches.

# Problem 2

Read and clean the NYC Transit dataset.

``` r
NYC_transit_df = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
NYC_transit_df = janitor::clean_names(NYC_transit_df)
```

Choose some columns and not others.

``` r
select(NYC_transit_df, line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada)
```

    ## # A tibble: 1,868 x 19
    ##    line  station_name station_latitude station_longitu… route1 route2 route3
    ##    <chr> <chr>                   <dbl>            <dbl> <chr>  <chr>  <chr> 
    ##  1 4 Av… 25th St                  40.7            -74.0 R      <NA>   <NA>  
    ##  2 4 Av… 25th St                  40.7            -74.0 R      <NA>   <NA>  
    ##  3 4 Av… 36th St                  40.7            -74.0 N      R      <NA>  
    ##  4 4 Av… 36th St                  40.7            -74.0 N      R      <NA>  
    ##  5 4 Av… 36th St                  40.7            -74.0 N      R      <NA>  
    ##  6 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  7 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  8 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  9 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ## 10 4 Av… 53rd St                  40.6            -74.0 R      <NA>   <NA>  
    ## # … with 1,858 more rows, and 12 more variables: route4 <chr>, route5 <chr>,
    ## #   route6 <chr>, route7 <chr>, route8 <dbl>, route9 <dbl>, route10 <dbl>,
    ## #   route11 <dbl>, entry <chr>, vending <chr>, entrance_type <chr>, ada <lgl>

Now convert the entry variable from character to a logical variable.

``` r
NYC_transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry, "YES"="TRUE", "NO"="FALSE"), entry = as.logical(entry))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

The original data set contains 32 variables, which include character,
double and logical variables. First, I clean the name of each variable
to make them all in lower case. Then I only retain the line, station,
name, station latitude / longitude, routes served, entry, vending,
entrance type, and ADA compliance, which are the variables the question
interested in. After this step, there are only 19 variables left. Next,
I convert the “entry” from character variable to logical variable by
using “recode” function. The resulting data set has 1868 rows and 19
columns. These data are tidy now such that columns are variable names
all in lower case and single columns contain single variables.

``` r
nrow(distinct(NYC_transit_df, line, station_name, .keep_all = TRUE))
```

    ## [1] 465

``` r
count(filter(NYC_transit_df,ada == "TRUE"))
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   468

``` r
count(filter(NYC_transit_df, vending == "NO"))/sum(count(filter(NYC_transit_df, entry == "TRUE"))+count(filter(NYC_transit_df, entry == "FALSE")))
```

    ##            n
    ## 1 0.09796574

  - There are 465 distinct stations.
  - 468 stations are ADA compliant.
  - The proportion of station entrances / exits without vending allow
    entrance is 0.0980 or 9.80%.

# Problem 3

Read and clean the pols-month dataset.

``` r
pols_month_df = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, c("year","month", "day")) %>% 
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day)
  ) %>% 
  mutate(month = month.name[month]) %>% 
  mutate(president = prez_gop + prez_dem) %>% 
  select(-prez_gop, -prez_dem) %>% 
  select(-day)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

Read and clean the snp.csv dataset.

``` r
snp_df = 
  read_csv("./fivethirtyeight_datasets/snp.csv")%>% 
  janitor::clean_names() %>% 
  separate(date, c("month","day", "year")) %>% 
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day)
  ) %>% 
  mutate(month = month.name[month]) %>% 
  relocate(year, month)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Read and clean the unemployment dataset.

``` r
unemployment_df = 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") 
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
colnames(unemployment_df)[2:13] = month.name
```
