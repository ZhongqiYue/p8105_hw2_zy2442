Homework 2
================
Zhongqi Yue

``` r
library(tidyverse)
```

    ## ── Attaching packages ───────────────────────────────────────────────────────────── tidyverse 1.3.0 ──

    ## ✓ ggplot2 3.3.2     ✓ purrr   0.3.4
    ## ✓ tibble  3.0.3     ✓ dplyr   1.0.2
    ## ✓ tidyr   1.1.2     ✓ stringr 1.4.0
    ## ✓ readr   1.3.1     ✓ forcats 0.5.0

    ## ── Conflicts ──────────────────────────────────────────────────────────────── tidyverse_conflicts() ──
    ## x dplyr::filter() masks stats::filter()
    ## x dplyr::lag()    masks stats::lag()

``` r
library(readxl)
```

## Problem 1

Read the Mr. Trashwheel dataset.

``` r
trashwheel_df = 
  read_xlsx(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "Mr. Trash Wheel",
    range = cell_cols("A:N")) %>% 
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(
    sports_balls = round(sports_balls),
    sports_balls = as.integer(sports_balls)
  )
```

Read precipitation data for 2018 and 2017.

``` r
precip_2018 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2018 Precipitation",
    skip = 1
    ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2018) %>% 
  relocate(year)

precip_2017 =
  read_excel(
    "./data/Trash-Wheel-Collection-Totals-8-6-19.xlsx",
    sheet = "2017 Precipitation",
    skip = 1
    ) %>% 
  janitor::clean_names() %>% 
  drop_na(month) %>% 
  mutate(year = 2017) %>% 
  relocate(year)
```

Now combine annual precipitation.

``` r
month_df = 
  tibble(
    month = 1:12,
    month_name = month.name
  )

precip_df = 
  bind_rows(precip_2018,precip_2017) 

left_join(precip_df, month_df, by = "month" )
```

    ## # A tibble: 24 x 4
    ##     year month total month_name
    ##    <dbl> <dbl> <dbl> <chr>     
    ##  1  2018     1  0.94 January   
    ##  2  2018     2  4.8  February  
    ##  3  2018     3  2.69 March     
    ##  4  2018     4  4.69 April     
    ##  5  2018     5  9.27 May       
    ##  6  2018     6  4.77 June      
    ##  7  2018     7 10.2  July      
    ##  8  2018     8  6.45 August    
    ##  9  2018     9 10.5  September 
    ## 10  2018    10  2.12 October   
    ## # … with 14 more rows

This dataset contains information from the Mr. Trashwheel trash
collector in Baltimore, Maryland. As trash enters the inner harbor, the
trashwheel collects that trash, and stores it in a dumpster. The dataset
contains information on year, month, and trash collected, include some
specific kinds of trash. There are a total of 344 rows in our final
dataset. Additional data sheets include month precipitation data. The
median number of sports balls found in a dumpster in 2017 was 8 The
total precipitation in 2018 was 70.33 inches.

# Problem 2

Read and clean the NYC Transit dataset.

``` r
NYC_transit_df = read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

``` r
NYC_transit_df = janitor::clean_names(NYC_transit_df)
```

Choose some columns and not others.

``` r
select(NYC_transit_df, line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada)
```

    ## # A tibble: 1,868 x 19
    ##    line  station_name station_latitude station_longitu… route1 route2 route3
    ##    <chr> <chr>                   <dbl>            <dbl> <chr>  <chr>  <chr> 
    ##  1 4 Av… 25th St                  40.7            -74.0 R      <NA>   <NA>  
    ##  2 4 Av… 25th St                  40.7            -74.0 R      <NA>   <NA>  
    ##  3 4 Av… 36th St                  40.7            -74.0 N      R      <NA>  
    ##  4 4 Av… 36th St                  40.7            -74.0 N      R      <NA>  
    ##  5 4 Av… 36th St                  40.7            -74.0 N      R      <NA>  
    ##  6 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  7 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  8 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ##  9 4 Av… 45th St                  40.6            -74.0 R      <NA>   <NA>  
    ## 10 4 Av… 53rd St                  40.6            -74.0 R      <NA>   <NA>  
    ## # … with 1,858 more rows, and 12 more variables: route4 <chr>, route5 <chr>,
    ## #   route6 <chr>, route7 <chr>, route8 <dbl>, route9 <dbl>, route10 <dbl>,
    ## #   route11 <dbl>, entry <chr>, vending <chr>, entrance_type <chr>, ada <lgl>

Now convert the entry variable from character to a logical variable.

``` r
NYC_transit_df = 
  read_csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv") %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, route1, route2, route3, route4, route5, route6, route7, route8, route9, route10, route11, entry, vending, entrance_type, ada) %>% 
  mutate(entry = recode(entry, "YES"="TRUE", "NO"="FALSE"), entry = as.logical(entry))
```

    ## Parsed with column specification:
    ## cols(
    ##   .default = col_character(),
    ##   `Station Latitude` = col_double(),
    ##   `Station Longitude` = col_double(),
    ##   Route8 = col_double(),
    ##   Route9 = col_double(),
    ##   Route10 = col_double(),
    ##   Route11 = col_double(),
    ##   ADA = col_logical(),
    ##   `Free Crossover` = col_logical(),
    ##   `Entrance Latitude` = col_double(),
    ##   `Entrance Longitude` = col_double()
    ## )

    ## See spec(...) for full column specifications.

The original data set contains 32 variables, which include character,
double and logical variables. First, I clean the name of each variable
to make them all in lower case. Then I only retain the line, station,
name, station latitude / longitude, routes served, entry, vending,
entrance type, and ADA compliance, which are the variables the question
interested in. After this step, there are only 19 variables left. Next,
I convert the “entry” from character variable to logical variable by
using “recode” function. The resulting data set has 1868 rows and 19
columns. These data are tidy now such that columns are variable names
all in lower case and single columns contain single variables.

``` r
count(distinct(NYC_transit_df, line, station_name, .keep_all = TRUE))
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   465

``` r
count(filter(NYC_transit_df,ada == "TRUE"))
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1   468

``` r
count(filter(NYC_transit_df, entry == "TRUE", vending == "NO"))/count(filter(NYC_transit_df, vending == "NO"))
```

    ##           n
    ## 1 0.3770492

  - There are 465 distinct stations.
  - 468 stations are ADA compliant.
  - The proportion of station entrances / exits without vending allow
    entrance is 0.3770492 or 37.70492%.

Reformat the data.

``` r
Reformed_df = 
  NYC_transit_df %>% 
  mutate_at(vars(route1:route11), as.character) %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_name",
    names_prefix = "route_name",
    values_to = "route_number") %>% 
  drop_na(route_number) 

Reformed_df%>% 
  filter(route_number == "A") %>% 
  distinct(line, station_name) %>% 
  count()
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    60

``` r
Reformed_df%>% 
  filter(route_number == "A") %>% 
  distinct(line, station_name, ada) %>%
  filter(ada == "TRUE") %>% 
  count()
```

    ## # A tibble: 1 x 1
    ##       n
    ##   <int>
    ## 1    17

  - After reformatting the data set, there are 60 distinct stations
    serve the A train. Of the stations that serve the A train, only 17
    are ADA compliant.

# Problem 3

Read and clean the pols-month dataset.

``` r
pols_month_df = 
  read_csv("./fivethirtyeight_datasets/pols-month.csv") %>% 
  janitor::clean_names() %>% 
  separate(mon, c("year","month", "day")) %>% 
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day)
  ) %>% 
  mutate(month = month.name[month]) %>% 
  mutate(president =prez_dem, prez_gop)%>% 
  mutate(president = recode(president,"1" = "dem", "0" = "gop")) %>% 
  select(-prez_gop, -prez_dem) %>% 
  select(-day)
```

    ## Parsed with column specification:
    ## cols(
    ##   mon = col_date(format = ""),
    ##   prez_gop = col_double(),
    ##   gov_gop = col_double(),
    ##   sen_gop = col_double(),
    ##   rep_gop = col_double(),
    ##   prez_dem = col_double(),
    ##   gov_dem = col_double(),
    ##   sen_dem = col_double(),
    ##   rep_dem = col_double()
    ## )

Read and clean the snp.csv dataset.

``` r
snp_df = 
  read_csv("./fivethirtyeight_datasets/snp.csv")%>% 
  janitor::clean_names() %>% 
  separate(date, c("month","day", "year")) %>% 
  mutate(
    year = as.integer(year),
    month = as.integer(month),
    day = as.integer(day)
  ) %>% 
  mutate(month = month.name[month]) %>% 
  relocate(year, month) %>% 
  select(-day)
```

    ## Parsed with column specification:
    ## cols(
    ##   date = col_character(),
    ##   close = col_double()
    ## )

Read and clean the unemployment dataset.

``` r
unemployment_df = 
  read_csv("./fivethirtyeight_datasets/unemployment.csv") 
```

    ## Parsed with column specification:
    ## cols(
    ##   Year = col_double(),
    ##   Jan = col_double(),
    ##   Feb = col_double(),
    ##   Mar = col_double(),
    ##   Apr = col_double(),
    ##   May = col_double(),
    ##   Jun = col_double(),
    ##   Jul = col_double(),
    ##   Aug = col_double(),
    ##   Sep = col_double(),
    ##   Oct = col_double(),
    ##   Nov = col_double(),
    ##   Dec = col_double()
    ## )

``` r
colnames(unemployment_df)[2:13] = month.name
```

Wide format to long format.

``` r
unemployment_df_tidy = 
  unemployment_df %>% 
  pivot_longer(
    January : December,
    names_to = "month",
    values_to = "unemployment"
  ) %>% 
  janitor::clean_names()
```

Joining three datasets.

``` r
pols_snp_df=
  left_join(pols_month_df, snp_df, by =c("year","month"))
pols_snp_unemployment_df =
  left_join(pols_snp_df, unemployment_df_tidy, by =c("year", "month"))
```

  - The original pols-month data set contains 9 variables, which are
    mon, prez\_gop, gov\_gop,sen\_gop, rep\_gop, prez\_dem, gov\_dem,
    sen\_dem, rep\_dem.Among these variables, mon is date and the rest
    are double variables. After cleaning the data set, mon variable is
    separated into integer variables year, month and day. Then month
    number is replaced with the month name, which turns it into a
    character variable. A president variable is created to present
    prez\_dem and prez\_gop variables. Then prez\_dem, prez\_gop and day
    variables are removed.The final pols-month data set contains 9
    varibales, which are year (integer variable), month (character
    varibale), president (character variable), gov\_gop, sen\_gop,
    rep\_gop, gov\_dem, sen\_dem, rep\_dem (the rest are all double
    variables). The final dimension (rows, columns) of this data set is
    (822, 9).
  - The original snp data set contains two variables, which are date
    (character variable) and close (double variable). By applying the
    same cleaning step, this data set is turned into three variables,
    which are year (integer variable), month (character variable) and
    close (double variable). The final dimension (rows, columns) of this
    data set is (787, 3).
  - The original unemployment data set contains 13 variables, which are
    year, Jan - Dec (all 13 variables are double variables). Then the
    wide format is turned into the long format so that we have three
    variables, which are year (double variable), month (character
    variable) and unemployment (double variable). The final dimension
    (rows, columns) of this data set is (816, 3).
  - The dimension (rows, columns) of the final data set is (822, 11).
    The range of the year is (1947, 2015). The names of key variables
    are “year” and “month”.
